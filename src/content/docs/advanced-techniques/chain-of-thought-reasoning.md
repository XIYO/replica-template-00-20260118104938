---
title: "생각의 사슬(Chain-of-Thought) 추론"
description: "모델이 문제를 단계별로 해결하도록 유도하여 복잡한 논리적 추론 능력을 극대화하는 프롬프트 전략을 알아봅니다."
---

## 개요

**생각의 사슬(Chain-of-Thought, CoT)**은 거대 언어 모델(LLM)이 복잡한 문제를 해결할 때, 최종 정답을 내놓기 전 중간 단계의 추론 과정을 생성하도록 유도하는 기술입니다. 이는 모델이 인간처럼 논리적 흐름을 따라가며 문제를 해결하게 함으로써 산술, 상식, 상징적 추론 작업의 성능을 비약적으로 향상시킵니다.

## CoT의 주요 기법

### 1. Zero-shot CoT
별도의 예시 없이 프롬프트에 특정 문구를 추가하여 모델의 추론을 활성화합니다. 가장 널리 알려진 마법의 문구는 다음과 같습니다.
- **"단계별로 차근차근 생각해 보세요 (Let's think step by step)"**

이 한 문장만으로도 모델은 결론을 서두르지 않고 논리적인 단계를 밟아 답변을 구성하게 됩니다.

### 2. Few-shot CoT
사용자가 '문제-추론 과정-정답'으로 구성된 예시(Few-shot)를 직접 제공하는 방식입니다. 모델은 제공된 예시의 사고 방식을 학습하여 새로운 문제에도 동일한 논리 구조를 적용합니다.

## 실용적인 활용 예제

복잡한 산술 문제를 해결해야 하는 상황을 가정해 보겠습니다.

### 일반적인 프롬프트 (오류 가능성 높음)
> **질문:** 민수는 사과 10개를 가지고 있었습니다. 영희에게 3개를 주고, 시장에서 5개를 더 샀습니다. 그 후 친구 2명에게 사과를 각각 2개씩 나누어 주었습니다. 민수에게 남은 사과는 몇 개인가요?
> **결과:** 8개입니다. (단계가 복잡할수록 단순 예측으로 인한 오답 발생)

### CoT를 적용한 프롬프트
> **질문:** 민수는 사과 10개를 가지고 있었습니다. [중략] 남은 사과는 몇 개인가요? **단계별로 추론 과정을 포함하여 답해 주세요.**

> **응답:**
> 1. 처음 가진 사과: 10개
> 2. 영희에게 3개를 줌: 10 - 3 = 7개
> 3. 시장에서 5개를 추가 구매: 7 + 5 = 12개
> 4. 친구 2명에게 각각 2개씩 줌: 2 * 2 = 4개 지출
> 5. 최종 계산: 12 - 4 = 8개
> **정답:** 민수에게 남은 사과는 8개입니다.

## CoT 전략의 장점

- **정확도 향상:** 복잡한 다단계 문제에서 계산 실수나 논리적 비약을 방지합니다.
- **해석 가능성(Interpretability):** 모델이 왜 그런 결론에 도달했는지 사용자가 과정을 추적하고 검증할 수 있습니다.
- **디버깅 용이성:** 추론 과정 중 어느 단계에서 오류가 발생했는지 파악하여 프롬프트를 수정하기 쉽습니다.

## 권장 사항

1. **수학 및 코딩:** 알고리즘이나 수식을 풀 때 반드시 사용하세요.
2. **상식 추론:** 전제 조건이 많은 시나리오 분석에 효과적입니다.
3. **자기 일관성(Self-Consistency) 결합:** 동일한 질문에 대해 CoT로 여러 번 답변을 생성하게 한 뒤, 가장 많이 나온 답을 선택하면 신뢰도가 더욱 높아집니다.